{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5c9b0fcf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler,MinMaxScaler, OneHotEncoder, KBinsDiscretizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import jaccard_score, pairwise_distances\n",
    "\n",
    "from scipy.spatial.distance import cosine\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5036afcd",
   "metadata": {},
   "source": [
    "Part I: Based on Feature Selection, Cleaning, and Preprocessing to Construct an Input from Data\n",
    "Source\n",
    "(a) Examine the values of each attribute and Select a set of attributes only that would affect to predict\n",
    "future bike buyers to create your input for data mining algorithms. Remove all the unnecessary\n",
    "attributes. (Select features just by analysis)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e70f0764",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                          \n",
    "!{sys.executable} -m pip install kagglehub"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ce696ea3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import kagglehub"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a077fa6f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading from https://www.kaggle.com/api/v1/datasets/download/jahias/microsoft-adventure-works-cycles-customer-data?dataset_version_number=1...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 939k/939k [00:00<00:00, 1.14MB/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting files...\n",
      "Path to dataset files: C:\\Users\\Ojasvin\\.cache\\kagglehub\\datasets\\jahias\\microsoft-adventure-works-cycles-customer-data\\versions\\1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Download Latest Version\n",
    "path = kagglehub.dataset_download(\"jahias/microsoft-adventure-works-cycles-customer-data\")\n",
    "\n",
    "print(\"Path to dataset files:\", path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "19498c01",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_customers = pd.read_csv(os.path.join(path,'AWCustomers.csv'))\n",
    "data_sales = pd.read_csv(os.path.join(path,'AWSales.csv'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35adea47",
   "metadata": {},
   "source": [
    "We'll concatenate the 2 dataframes Sales and Customers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "53e935cd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['CustomerID', 'BikeBuyer', 'AvgMonthSpend'], dtype='object')\n",
      "Index(['CustomerID', 'Title', 'FirstName', 'MiddleName', 'LastName', 'Suffix',\n",
      "       'AddressLine1', 'AddressLine2', 'City', 'StateProvinceName',\n",
      "       'CountryRegionName', 'PostalCode', 'PhoneNumber', 'BirthDate',\n",
      "       'Education', 'Occupation', 'Gender', 'MaritalStatus', 'HomeOwnerFlag',\n",
      "       'NumberCarsOwned', 'NumberChildrenAtHome', 'TotalChildren',\n",
      "       'YearlyIncome', 'LastUpdated'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "print(data_sales.columns)\n",
    "print(data_customers.columns)\n",
    "\n",
    "# to avoid having 2 custId column, we will drop it\n",
    "data_sales.drop(['CustomerID'],axis = 1, inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "4f86e5ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.concat([data_customers,data_sales],axis= 1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "293cf477",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['CustomerID', 'Title', 'FirstName', 'MiddleName', 'LastName', 'Suffix',\n",
       "       'AddressLine1', 'AddressLine2', 'City', 'StateProvinceName',\n",
       "       'CountryRegionName', 'PostalCode', 'PhoneNumber', 'BirthDate',\n",
       "       'Education', 'Occupation', 'Gender', 'MaritalStatus', 'HomeOwnerFlag',\n",
       "       'NumberCarsOwned', 'NumberChildrenAtHome', 'TotalChildren',\n",
       "       'YearlyIncome', 'LastUpdated', 'BikeBuyer', 'AvgMonthSpend'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ffad14bf",
   "metadata": {},
   "source": [
    "Useless Columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "b6dcb0ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop(['Title','Suffix','Education','Occupation','PhoneNumber','MiddleName','AddressLine2'],axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "1132ea53",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['CustomerID', 'FirstName', 'LastName', 'AddressLine1', 'City',\n",
       "       'StateProvinceName', 'CountryRegionName', 'PostalCode', 'BirthDate',\n",
       "       'Gender', 'MaritalStatus', 'HomeOwnerFlag', 'NumberCarsOwned',\n",
       "       'NumberChildrenAtHome', 'TotalChildren', 'YearlyIncome', 'LastUpdated',\n",
       "       'BikeBuyer', 'AvgMonthSpend'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# now, leftover columns\n",
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "3fe1b16f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Discrete Variables :  ['CustomerID', 'HomeOwnerFlag', 'NumberCarsOwned', 'NumberChildrenAtHome', 'TotalChildren', 'YearlyIncome']\n",
      "Continuous Variables :  ['BikeBuyer', 'AvgMonthSpend']\n"
     ]
    }
   ],
   "source": [
    "# Classifying the Variables into discrete and continuous\n",
    "\n",
    "var_cat = [] #categorical\n",
    "var_num = [] #numerical\n",
    "\n",
    "for c in df.columns:\n",
    "    if df[c].dtype == 'float64':\n",
    "        var_cat.append(c)\n",
    "    if df[c].dtype == 'int64':\n",
    "        var_num.append(c)\n",
    "\n",
    "print (\"Discrete Variables : \", var_num)\n",
    "print (\"Continuous Variables : \", var_cat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "1a500ece",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nominal:  ['CustomerID', 'FirstName', 'LastName', 'AddressLine1', 'City', 'StateProvinceName', 'CountryRegionName', 'PostalCode', 'Gender', 'MaritalStatus', 'HomeOwnerFlag', 'BikeBuyer']\n",
      "Ordinal:  []\n",
      "Ratio:  ['NumberCarsOwned', 'NumberChildrenAtHome', 'TotalChildren', 'YearlyIncome', 'AvgMonthSpend']\n",
      "Interval:  ['BirthDate']\n"
     ]
    }
   ],
   "source": [
    "# Classification of Datatypes\n",
    "Nominal = [\n",
    "    'CustomerID',\n",
    "    'FirstName',\n",
    "    'LastName',\n",
    "    'AddressLine1',\n",
    "    'City',\n",
    "    'StateProvinceName',\n",
    "    'CountryRegionName',\n",
    "    'PostalCode',\n",
    "    'Gender',\n",
    "    'MaritalStatus',\n",
    "    'HomeOwnerFlag',\n",
    "    'BikeBuyer'\n",
    "]\n",
    "Ordinal=[]\n",
    "Ratio = [\n",
    "    'NumberCarsOwned',\n",
    "    'NumberChildrenAtHome',\n",
    "    'TotalChildren',\n",
    "    'YearlyIncome',\n",
    "    'AvgMonthSpend'\n",
    "]\n",
    "Interval=['BirthDate']\n",
    "print(\"Nominal: \",Nominal)\n",
    "print(\"Ordinal: \",Ordinal)\n",
    "print(\"Ratio: \",Ratio)\n",
    "print(\"Interval: \",Interval)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "087c6d87",
   "metadata": {},
   "source": [
    "Part II: Data Preprocessing and Transformation\n",
    "Depending on the data type of each attribute, transform each object from your preprocessed data.\n",
    "Use all the data rows (~= 18000 rows) with the selected features as input to apply all the tasks below, do\n",
    "not perform each task on the smaller data set that you got from your random sampling result.\n",
    "(a) Handling Null values\n",
    "(b) Normalization\n",
    "(c) values\n",
    "(d) Standardization/Normalization\n",
    "(e) Binarization (One Hot Encoding)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21311a27",
   "metadata": {},
   "source": [
    "---------------------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca07b1f4",
   "metadata": {},
   "source": [
    "- Handling Null Values"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d708c78",
   "metadata": {},
   "source": [
    "An imputer in machine learning is a tool or method used to fill in missing values in your dataset so you can train a model without errors or bias from incomplete data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "0543b18b",
   "metadata": {},
   "outputs": [],
   "source": [
    "numerical_features = ['YearlyIncome', 'AvgMonthSpend', 'NumberCarsOwned', 'NumberChildrenAtHome', 'TotalChildren']\n",
    "categorical_features = ['Gender', 'MaritalStatus', 'HomeOwnerFlag', 'BikeBuyer']\n",
    "\n",
    "numerical_imputer = SimpleImputer(strategy='mean')\n",
    "categorical_imputer = SimpleImputer(strategy='most_frequent')\n",
    "\n",
    "\n",
    "df[numerical_features] = numerical_imputer.fit_transform(df[numerical_features])\n",
    "df[categorical_features] = categorical_imputer.fit_transform(df[categorical_features])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "afef6552",
   "metadata": {},
   "source": [
    "- Normalization of Values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "099d056c",
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = MinMaxScaler()\n",
    "df[numerical_features] = scaler.fit_transform(df[numerical_features])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69a12436",
   "metadata": {},
   "source": [
    "- Standardization\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "a197b937",
   "metadata": {},
   "outputs": [],
   "source": [
    "standard_scaler = StandardScaler()\n",
    "df[numerical_features] = standard_scaler.fit_transform(df[numerical_features])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b46fcdfe",
   "metadata": {},
   "source": [
    "- Binning/ Discretization \n",
    "on continuous attributes / or Discrete attributes with too many values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f93a8534",
   "metadata": {},
   "outputs": [],
   "source": [
    "binning_transformer = KBinsDiscretizer(n_bins=3, encode='ordinal', strategy='uniform')\n",
    "df['YearlyIncome_Binned'] = binning_transformer.fit_transform(df[['YearlyIncome']])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd7e310f",
   "metadata": {},
   "source": [
    "- One Hot Encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "ecd8bea7",
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder = OneHotEncoder(sparse_output=False)\n",
    "categorical_features = ['Gender', 'MaritalStatus', 'HomeOwnerFlag', 'BikeBuyer']\n",
    "encoded_categorical_features = encoder.fit_transform(df[categorical_features])\n",
    "encoded_df = pd.DataFrame(encoded_categorical_features, columns=encoder.get_feature_names_out(categorical_features))\n",
    "df = pd.concat([df, encoded_df], axis=1).drop(categorical_features, axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b4f4a2c",
   "metadata": {},
   "source": [
    "Part III: Calculating Proximity /Correlation Analysis of two features\n",
    "Make sure each attribute is transformed in a same scale for numeric attributes and Binarization for each\n",
    "nominal attribute, and each discretized numeric attribute to standardization. Make sure to apply a correct\n",
    "similarity measure for nominal (one hot encoding)/binary attributes and numeric attributes respectively.\n",
    "(a) Calculate Similarity in Simple Matching, Jaccard Similarity, and Cosine Similarity between two\n",
    "following objects of your transformed input data.\n",
    "(b) Calculate Correlation between two features Commute Distance and Yearly Income"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "2a76480d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def jaccard(list1, list2):\n",
    "    intersection = len(list(set(list1).intersection(list2)))\n",
    "    union = (len(list1) + len(list2)) - intersection\n",
    "    return float(intersection) / union\n",
    "\n",
    "# calling the function JACCARD\n",
    "jaccard(df['YearlyIncome'],df['AvgMonthSpend'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "c2417b99",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Jaccard Similarity between NumberChildrenAtHome_Binary and BikeBuyer_0.0: 0.2138122536725188\n",
      "Jaccard Similarity between NumberChildrenAtHome_Binary and BikeBuyer_1.0: 0.23450479233226837\n"
     ]
    }
   ],
   "source": [
    "df['NumberChildrenAtHome_Binary'] = (df['NumberChildrenAtHome'] > 0).astype(int)\n",
    "# Compute Jaccard Similarity between 'NumberChildrenAtHome_Binary' and each 'BikeBuyer' column\n",
    "for bike_buyer_col in ['BikeBuyer_0.0', 'BikeBuyer_1.0']:\n",
    "    jaccard_sim = jaccard_score(df['NumberChildrenAtHome_Binary'], df[bike_buyer_col])\n",
    "    print(f\"Jaccard Similarity between NumberChildrenAtHome_Binary and {bike_buyer_col}: {jaccard_sim}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "524b2a33",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.012200386558915567"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['YearlyIncome'].corr(df['AvgMonthSpend'])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
